{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4c823c-bc23-4511-9e5d-7d45972ce150",
   "metadata": {
    "tags": []
   },
   "source": [
    "## KennGlacHobosCorrection.ipynb, Kennicott Glacier hobo corrections \n",
    "\n",
    "This code imports data from four hobo loggers that were left out on Kennicott Glacier in 2021 (\"KennGlacHobosData.xlsx\").\n",
    "\n",
    "It first plots then data, then slices off the section at end of season when the four sensors experienced identical temperatures (10/1-10/4/2021). It compares these records and corrects three of the sensors very slightly so that they are all essentially identical. It then applies that correction to the rest of the data from the summer to produce a good quality record of temps at all stations. \n",
    "\n",
    "Then it compares the Gates AWS hobo to the Gates AWS NPS (long-term record), finds them close but not identical, so does a regression to predict Gates AWS (hobo)\n",
    "from the NPS station. I apply that regression to ALL hobos since they presumably all have that same offset.\n",
    "\n",
    "Finally it saves the corrected values, for only the period of good data on the glacier (6/11/2021 17:00 to 9/8/2021 12:00), as a pickle file (homogenized_hobos.pickle) which contains a pandas table, homogenized, with fields Gates3600_degC (corrected), Kenn6100_degC (corrected), GatesAWS_degC (uncorrected), and ChineseAWS_degC (corrected). It also has GatesNPS_degC, which is the raw data from the NPS weather station.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0aca77-d7ca-4907-bee4-6010a06ed3af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## IMPORT PACKAGES\n",
    "\n",
    "# standard\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os, csv\n",
    "\n",
    "# specialized\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "# statsmodels is a nice tool for regressions\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from numpy.polynomial import Chebyshev\n",
    "from numpy.polynomial.chebyshev import chebfit\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# set default figure size\n",
    "figsize=(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615081bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LOAD DATA\n",
    "\n",
    "# set working directory\n",
    "data_dir = r'~/MLo/KennGlac/data'\n",
    "# Load an excel workbook that is in the local directory\n",
    "xlsx=pd.ExcelFile(os.path.join(data_dir,'KennGlacHobosData.xlsx'))\n",
    "# Load the first worksheet as 'wb', treat -9999 as nan|, make first column (dates) the index\n",
    "wb=pd.read_excel(xlsx,sheet_name='Sheet1',na_values=[-9999],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dac84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## VIEW DATA\n",
    "\n",
    "# # Print summary of worksheet (2 first 2 last rows)\n",
    "# print(wb.head(2))\n",
    "\n",
    "# # Print datatypes (dtypes) of DataFrame (wb)\n",
    "# print(wb.dtypes)\n",
    "\n",
    "## PLOT\n",
    "# set up for subplots\n",
    "fig,axs = plt.subplots(1,2,sharey=True,figsize=(16,8))\n",
    "\n",
    "# Plot all data in left panel\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(wb)\n",
    "\n",
    "# Select data from specific range\n",
    "## INPUT: Choose start and end times ## This is the time of overlap for the hobos at end of season\n",
    "startoverlap = pd.to_datetime('10/1/2021 18:00')\n",
    "endoverlap = pd.to_datetime('10/4/2021 05:00')\n",
    "\n",
    "# create 'overlap', a table of just the time when all the sensors were in the same place\n",
    "overlap=wb[(startoverlap) : (endoverlap)]\n",
    "    \n",
    "# Plot data from that range in right panel\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(overlap)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72c9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PERFORM REGRESSION AND VIEW RESULTS \n",
    "\n",
    "# This is a cumbersome way to do it, but it worked. So leaving it. \n",
    "\n",
    "# call Gates AWS the \"right\" value since it is our most stable and consistent measurement\n",
    "# start with Gates3600 eg. x=rng['Gates AWS degC']. Make it into an array and reshape it as column\n",
    "# probably a better way to do this\n",
    "x=np.asarray(overlap['Gates AWS degC'])\n",
    "x=x.reshape(-1,1)\n",
    "y1=np.asarray(overlap['Gates 3600 degC'])\n",
    "y1=y1.reshape(-1,1)\n",
    "y2=np.asarray(overlap['Kenn 6100 degC'])\n",
    "y2=y2.reshape(-1,1)\n",
    "y3=np.asarray(overlap['Chinese AWS degC'])\n",
    "y3=y3.reshape(-1,1)\n",
    "\n",
    "\n",
    "# define a 1:1 line for plotting\n",
    "xline=[0,20]\n",
    "yline=[0,20]\n",
    "\n",
    "\n",
    "# FIT AND PLOT MODELS\n",
    "\n",
    "# Gates 3600 (how do we change y1 to get x)\n",
    "regr1=linear_model.LinearRegression()\n",
    "regr1.fit(y1,x)\n",
    "y1_pred=regr1.predict(y1)\n",
    "# save stats\n",
    "print('Coefficients:', regr1.coef_)\n",
    "# save coefficients\n",
    "intercepts=(regr1.intercept_)\n",
    "coefs=(regr1.coef_)\n",
    "print('Mean squared error: %.2f'\n",
    "         % mean_squared_error(x,y1_pred))\n",
    "print('Coefficient of determination: %.2f'\n",
    "         % r2_score(y1,y1_pred))\n",
    "# plot it\n",
    "fig,ax=plt.subplots()\n",
    "fig=plt.scatter(x,y1)\n",
    "fig=plt.plot(x,y1_pred,linewidth=0.5)\n",
    "# plot one to one line\n",
    "plt.plot(xline,yline,linestyle='--')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y1')\n",
    "ax.axis('tight')\n",
    "\n",
    "\n",
    "# Kenn 6100 (how do we change y2 to get x)\n",
    "regr2=linear_model.LinearRegression()\n",
    "regr2.fit(y2,x)\n",
    "y2_pred=regr2.predict(y2)\n",
    "# save stats\n",
    "print('Coefficients:', regr2.coef_)\n",
    "# save coefficients\n",
    "intercepts=np.append(intercepts,regr2.intercept_)\n",
    "coefs=np.append(coefs,regr2.coef_)\n",
    "print('Mean squared error: %.2f'\n",
    "         % mean_squared_error(x,y2_pred))\n",
    "print('Coefficient of determination: %.2f'\n",
    "         % r2_score(y2,y2_pred))\n",
    "# plot it\n",
    "fig,ax=plt.subplots()\n",
    "fig=plt.scatter(x,y2)\n",
    "fig=plt.plot(x,y2_pred,linewidth=0.5)\n",
    "# plot one to one line\n",
    "plt.plot(xline,yline,linestyle='--')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y2')\n",
    "ax.axis('tight')\n",
    "\n",
    "# Chinese AWS (how do we change y3 to get x)\n",
    "regr3=linear_model.LinearRegression()\n",
    "regr3.fit(y3,x)\n",
    "y3_pred=regr3.predict(y3)\n",
    "# save stats\n",
    "print('Coefficients:', regr3.coef_)\n",
    "# save coefficients\n",
    "intercepts=np.append(intercepts,regr3.intercept_)\n",
    "coefs=np.append(coefs,regr3.coef_) \n",
    "print('Mean squared error: %.2f'\n",
    "         % mean_squared_error(x,y3_pred))\n",
    "print('Coefficient of determination: %.2f'\n",
    "         % r2_score(y3,y3_pred))\n",
    "# plot it\n",
    "fig,ax=plt.subplots()\n",
    "fig=plt.scatter(x,y3)\n",
    "fig=plt.plot(x,y3_pred,linewidth=0.5)\n",
    "# plot one to one line\n",
    "plt.plot(xline,yline,linestyle='--')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y3')\n",
    "ax.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d3880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# APPLY REGRESSION COEFFICIENTS TO ORIGINAL DATA AND PLOT\n",
    "# to do so, convert pandas tables to arrays using *.array\n",
    "\n",
    "\n",
    "# y1fixed, y2fixed, and y3 fixed are the corrected versions \n",
    "# Gates\n",
    "temp1=np.array(wb['Gates 3600 degC'])\n",
    "temp1=temp1.reshape(-1,1)\n",
    "y1fixed=regr1.predict(temp1)\n",
    "y1fixed=y1fixed.flatten()\n",
    "\n",
    "# Kenn 6100\n",
    "temp2=np.array(wb['Kenn 6100 degC'])\n",
    "temp2=temp2.reshape(-1,1)\n",
    "y2fixed=regr2.predict(temp2)\n",
    "y2fixed=y2fixed.flatten()\n",
    "\n",
    "# Chinese AWS (have to remove NaNs)\n",
    "temp3=np.array(wb['Chinese AWS degC'])\n",
    "# Chinese data has some NaNs and \"reshape' can't handle that. use this to harvest out just the real numbers\n",
    "# find nans and change to zeros\n",
    "nans2=np.argwhere(np.isnan(temp3))\n",
    "temp3[nans2]=0\n",
    "\n",
    "# run regression\n",
    "temp3=temp3.reshape(-1,1)\n",
    "y3fixed=regr3.predict(temp3)\n",
    "y3fixed=y3fixed.flatten()\n",
    "\n",
    "# need to remove 0 values from Chinese AWs\n",
    "nans2=nans2.flatten()\n",
    "y3fixed[nans2]=np.nan\n",
    "\n",
    "wb['Gates 3600 degC fixed']=y1fixed.tolist()\n",
    "wb['Kenn 6100 degC fixed']=y2fixed.tolist()\n",
    "wb['Chinese AWS degC fixed']=y3fixed.tolist()\n",
    "\n",
    "# Plot all data on same axis\n",
    "wb.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ad9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PLOT CORRECTED VERSIONS WITH ORIGINALS ON SHORT TIME SLICE\n",
    "fig,ax = plt.subplots(2,1,figsize=(12,12))\n",
    "\n",
    "\n",
    "OLDlab=wb.loc[datetime.datetime(2021,10,1,18,0,0):datetime.datetime(2021,10,4,5,0,0),['Gates 3600 degC','Kenn 6100 degC','Gates AWS degC','Chinese AWS degC']]\n",
    "plt.subplot(2,1,1)\n",
    "fig=plt.plot(OLDlab)\n",
    "ax[0].set_title('uncorrected')\n",
    "\n",
    "NEWlab=wb.loc[datetime.datetime(2021,10,1,18,0,0):datetime.datetime(2021,10,4,5,0,0),['Gates 3600 degC fixed','Kenn 6100 degC fixed','Gates AWS degC','Chinese AWS degC fixed']]\n",
    "plt.subplot(2,1,2)\n",
    "fig=plt.plot(NEWlab)\n",
    "ax[1].set_title('corrected')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8428523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PLOT CORRECTED VERSIONS (only) ON GOOD COMPARABLE TIME SLICE\n",
    "\n",
    "# Select data from specific range\n",
    "NEWfield=wb.loc[datetime.datetime(2021,6,11,17,0,0):datetime.datetime(2021,9,8,12,0,0),['Gates 3600 degC fixed','Kenn 6100 degC fixed','Gates AWS degC','Chinese AWS degC fixed']]\n",
    "# Plot data from that range\n",
    "NEWfield.plot();\n",
    "\n",
    "# Check for isnans (there aren't any)\n",
    "# find nans and change to zeros\n",
    "temp=np.array(NEWfield)\n",
    "nans5=np.argwhere(np.isnan(temp))\n",
    "print(nans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3d5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TURN CORRECTED VERSION ON GOOD TIMESLICE INTO NEW PANDAS TABLE \"HOMOGENIZED\" \n",
    "\n",
    "# NEWfield is the timesliced table. Rename column headers\n",
    "dict = {'Gates 3600 degC fixed': 'Gates3600_degC', 'Gates AWS degC': 'GatesAWS_degC', 'Kenn 6100 degC fixed': 'Kenn6100_degC', 'Chinese AWS degC fixed': 'ChineseAWS_degC'}\n",
    "NEWfield.rename(columns=dict,inplace=True)\n",
    "\n",
    "# Rename table\n",
    "homogenized=NEWfield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a1822-7168-48c2-80c8-e4b8eecf1a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TAKE ALL THE HOMOGENIZED HOBO RECORDS AND HOMOGENIZE THEM WITH THE GATES AWS RECORD\n",
    "## DO SO BY FINDING THE RIGHT REGRESSION BETWEEN GATES AWS (HOBO) AND GATES AWS (NPS LONG-TERM)\n",
    "## THEN APPLY CORRECTION TO ALL THE HOBOS\n",
    "\n",
    "# First load Gates long-term AWS record\n",
    "# set working directory\n",
    "data_dir = r'~/MLo/KennGlac/data/Raw_Climate_Records/current 2021/GATES hrly all vars 2016_01_01 to 2021_11_10/from telemetry'\n",
    "# Load an excel workbook that is in the local directory\n",
    "csv=os.path.join(data_dir,'GGLA2.2021-11-10.csv')\n",
    "# Load the first worksheet as 'wb', treat -9999 as nan|, make first column (dates) the index\n",
    "nps=pd.read_csv(csv,skiprows=[11],na_values=[-9999],header=10,parse_dates=['Date_Time'])\n",
    "# convert zulu time to AK Time\n",
    "nps.loc[:,'AKdate'] = nps['Date_Time'].dt.tz_convert('US/Alaska')\n",
    "# shift timestamp 33 minutes to read on the hour\n",
    "nps.AKdate = nps.AKdate - pd.Timedelta(33,'minutes') # on the hour\n",
    "# keep time as it is but remove time zone info (stays local AK)\n",
    "nps.loc[:,'AKdate'] = nps.AKdate.dt.tz_localize(tz=None)\n",
    "nps=nps.set_index(['AKdate'])\n",
    "\n",
    "# get slice of NPS long-term data that matches hobo data\n",
    "nps_hobo_overlap=nps.loc[datetime.datetime(2021,6,11,17,0,0):datetime.datetime(2021,9,8,12,0,0),['air_temp_set_1']]\n",
    "newcol=nps_hobo_overlap['air_temp_set_1']\n",
    "# add NPS data to homogenized\n",
    "homogenized = pd.concat([homogenized,newcol],axis = 1)\n",
    "# rename long-term data as GatesNPS_degC\n",
    "homogenized.rename(columns = {'air_temp_set_1':'GatesNPS_degC'},inplace=True)\n",
    "\n",
    "print(homogenized.head(2))\n",
    "\n",
    "## DO REGRESSION\n",
    "# Gates 3600 as a function of Gates AWS\n",
    "regr3=smf.ols(formula='GatesNPS_degC ~ GatesAWS_degC', data=homogenized).fit()\n",
    "\n",
    "print(regr3.params)\n",
    "print(regr3.summary())\n",
    "\n",
    "## PREDICT GATESAWS TEMPS DIRECTLY FROM GATESNPS\n",
    "homogenized['GatesAWSpredicted']=homogenized.GatesAWS_degC*regr3.params.GatesAWS_degC + regr3.params.Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8cd1f-d4dd-4a4f-8e34-931c16efda9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PLOT NUMBERS FOR VISUAL CONFIRMATION\n",
    "homogenized.plot(y=['GatesAWSpredicted','GatesAWS_degC','GatesNPS_degC'],ylabel='Temp degC',figsize=(12,10))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## COMPARE TIME SERIES FOR MATHEMATICAL CONFIRMATION\n",
    "## The tests below just verify that we improved the fit between the hobo and the nps sensor at Gates by doing the regression\n",
    "print('we expect diffraw2 to be smaller if the regression helped')\n",
    "diffraw1=homogenized.GatesNPS_degC-homogenized.GatesAWS_degC\n",
    "print(diffraw1.mean())\n",
    "diffraw2=homogenized.GatesNPS_degC-homogenized.GatesAWSpredicted\n",
    "print(diffraw2.mean())\n",
    "corr1=np.corrcoef(homogenized.GatesNPS_degC,homogenized.GatesAWS_degC)\n",
    "corr2=np.corrcoef(homogenized.GatesNPS_degC,homogenized.GatesAWSpredicted)\n",
    "print('we expect corr2 to be a better fit if the regression helped')\n",
    "print('%.8f' % corr1[1,1])\n",
    "print('%.8f' % corr2[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a44cae-af6e-4249-a3a9-bc61f0dc6761",
   "metadata": {},
   "source": [
    "### SUMMARY\n",
    "We developed a regression that can be used to move all the hobo data into the calibration frame of the Gates AWS station--our primary long-term reference.\n",
    "We don't want this to change the now-very good match between the sensors on all the hobos, so we will apply the regression to ALL the hobo records.\n",
    "\n",
    "Then we'll resave the homogenized dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46521b-a1ae-4bd2-b3cd-3535c4c89122",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREDICT ALL HOBO VALUES FROM GATES, THEN SAVE\n",
    "\n",
    "# make the conversions (already converted GatesAWS)\n",
    "homogenized['Gates3600predicted']=homogenized.Gates3600_degC*regr3.params.GatesAWS_degC + regr3.params.Intercept\n",
    "homogenized['ChineseAWSpredicted']=homogenized.ChineseAWS_degC*regr3.params.GatesAWS_degC + regr3.params.Intercept\n",
    "homogenized['Kenn6100predicted']=homogenized.Kenn6100_degC*regr3.params.GatesAWS_degC + regr3.params.Intercept\n",
    "\n",
    "# clean up homogenized\n",
    "del homogenized['Gates3600_degC']\n",
    "del homogenized['GatesAWS_degC']\n",
    "del homogenized['ChineseAWS_degC']\n",
    "del homogenized['Kenn6100_degC']\n",
    "\n",
    "homogenized.rename(columns = {'GatesAWSpredicted':'GatesAWS_degC'},inplace=True)\n",
    "homogenized.rename(columns = {'Gates3600predicted':'Gates3600_degC'},inplace=True)\n",
    "homogenized.rename(columns = {'Kenn6100predicted':'Kenn6100_degC'},inplace=True)\n",
    "homogenized.rename(columns = {'ChineseAWSpredicted':'ChineseAWS_degC'},inplace=True)\n",
    "\n",
    "# look good?\n",
    "print(homogenized.head())\n",
    "\n",
    "## save homogenized data to pickle\n",
    "# set working directory\n",
    "data_dir = r'/mnt/c/Users/MGLoso/Documents/software/KennGlac/data'\n",
    "\n",
    "# set pickle path (data_dir is directory, homogenized_hobos.pickle is dataset)\n",
    "homogenized_path = os.path.join(data_dir,'homogenized_hobos.pickle')\n",
    "\n",
    "# save variable dataframes\n",
    "homogenized.to_pickle(homogenized_path)\n",
    "\n",
    "# optional: save to csv\n",
    "# homogenized.to_csv(os.path.join(hobo_data,'homogenized.csv'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f707f187d25e9b0f6fa492aa37ad5851047050eb69207350f6aaa193bad4cd3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
